{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanoco/basketball-classification-dribbling/blob/main/creating_ts_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Running Libraries"
      ],
      "metadata": {
        "id": "WYVACTYBnWFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-98lb39ucDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import glob\n",
        "from sktime.datasets import write_ndarray_to_tsfile\n",
        "import os\n",
        "import math\n",
        "import random"
      ],
      "metadata": {
        "id": "fa_fb3onnVnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade sktime"
      ],
      "metadata": {
        "id": "8sQN7sxpnfPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6be98c9-f9d0-4b6a-b71b-4917b0999b20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sktime\n",
            "  Downloading sktime-0.27.0-py3-none-any.whl (21.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.9/21.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime) (23.2)\n",
            "Requirement already satisfied: pandas<2.2.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.5.3)\n",
            "Collecting scikit-base<0.8.0 (from sktime)\n",
            "  Downloading scikit_base-0.7.2-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.2/127.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<1.5.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.2.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.1->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.1->sktime) (2023.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=0.24->sktime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=0.24->sktime) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.2.0,>=1.1->sktime) (1.16.0)\n",
            "Installing collected packages: scikit-base, sktime\n",
            "Successfully installed scikit-base-0.7.2 sktime-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCtwsGyB6Y5b"
      },
      "source": [
        "## The Process of Creating a Dataset\n",
        "\n",
        "I will be using dummy data I created by moving my arm around for twelve seconds.\n",
        "This will be used to help me convert the CSV file recieved into a compatable .ts file type to be used for training.\n",
        "Once I have done this for the Accelerometer, Gyroscope and then finally both of them combined, I will proceed to create the actual training and testing dataset for the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc4d09vyFjbq",
        "outputId": "f4315179-4263-4327-82f0-1418f07ccbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAv4MSIo1GYJ"
      },
      "outputs": [],
      "source": [
        "# Converting CSV into a DataFrame for manipulation\n",
        "df_accel_data = pd.read_csv('/content/drive/MyDrive/Development_Project/dummy_data/Accelerometer.csv')\n",
        "#df_gyro_data = pd.read_csv('/content/drive/MyDrive/Development_Project/dummy_data/Gyroscope.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resampling the Seconds\n",
        "df_accel_data['seconds_elapsed'] = pd.to_datetime(df_accel_data['seconds_elapsed'], unit='s')\n",
        "\n",
        "df_accel_data.set_index('seconds_elapsed', inplace=True)\n",
        "\n",
        "df_resampled = df_accel_data.resample('S').mean()\n",
        "\n",
        "df_resampled.reset_index(inplace=True)\n",
        "\n",
        "df_resampled['seconds_elapsed'] = df_resampled['seconds_elapsed'].astype(int) / 1e6\n",
        "\n",
        "# Print the resampled DataFrame\n",
        "print(df_resampled)\n"
      ],
      "metadata": {
        "id": "h1oNnZsyPlxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping Columns\n",
        "\n",
        "Now, I must drop the necessary columns so that I only remain with; z,y and x."
      ],
      "metadata": {
        "id": "1s6Pg_FPIcT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_accel_data = df_accel_data.drop(columns=['time','seconds_elapsed'])"
      ],
      "metadata": {
        "id": "XKu6dNeFcZAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = df_resampled.drop(columns=['time','seconds_elapsed'])"
      ],
      "metadata": {
        "id": "xetiX3pSP_kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0FoZZENBq_A"
      },
      "source": [
        "## Normalisation; MinMax()\n",
        "\n",
        "I will apply Normalisation to this data. This will help with consistency in the future and aid in combatting biases the model may develop during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PbTUUdSB-y6"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Selecting the axes, scaling them with MinMaxScaler\n",
        "df_resampled[['z', 'y', 'x']] = scaler.fit_transform(df_resampled[['z', 'y', 'x']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1lWDqfMEoFm"
      },
      "source": [
        "## Establishing the labels (Y)\n",
        "\n",
        "Of course, each instance needs a label for the Classification models to be able to identify the movement performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3hBXHWJSE0K-"
      },
      "outputs": [],
      "source": [
        "label = 'test_1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmqflxEmE4Ja"
      },
      "source": [
        "## Exporting the data\n",
        "\n",
        "Finally, we want to be able to export this data into a suitable format. I have decided to use the .ts format from SKTime.\n",
        "\n",
        "A Time-Series file requires data in the format, specified in the documentation;\n",
        "\"The dataset in a 3d ndarray to be written as a ts file which must be of the structure specified in the documentation examples/loading_data.ipynb. (n_instances, n_columns, n_timepoints)\"\n",
        "\n",
        "As a result, I need to transpose the data so that the rows and columns are essentially flipped; 3 rows, n columns (n being the amount of timepoints, the 'rows' in this case are the columns z,y and x.)\n",
        "\n",
        "Then, once inserted into the array, the shape will match the format required\n",
        "\n",
        "*   (1 instance, 3 rows, n columns)\n",
        "*   \"(n_instances, n_columns, n_timepoints)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqzsLXdkIbDL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3wQzJYXyW_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_resampled = np.transpose(df_resampled)"
      ],
      "metadata": {
        "id": "k50N8gyXQK0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6RjmsDBFBkd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "X.append(df_resampled)\n",
        "y.append(label)\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "sy = set(y)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Development_Project/'\n",
        "write_ndarray_to_tsfile(data = X, path = file_path, problem_name='sample_data', class_label=sy,class_value_list=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Allowing for more than one instance.\n",
        "\n",
        "Now that we can successfully create one instance of a movement, insert it into a dataset and create that dataset, we now need to make it capable of iterating through numerous instances.\n",
        "\n",
        "This will consist of creating a loop, iterating through a folder of CSV files, preprocessing each one of them and appending it into the list.\n",
        "\n",
        "Once completed, we then convert that list into a numpy Array to then be packed away as a Time-Series dataset !"
      ],
      "metadata": {
        "id": "eEvG3v2WS5FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "AQFMmJDyV_nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []"
      ],
      "metadata": {
        "id": "CPNpjP0FW74J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/content/drive/MyDrive/Development_Project/dummy_data/'\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "\n",
        "  df_accel_data = pd.read_csv(path+file)\n",
        "  df_accel_data['seconds_elapsed'] = pd.to_datetime(df_accel_data['seconds_elapsed'], unit='s')\n",
        "  df_accel_data.set_index('seconds_elapsed', inplace=True)\n",
        "  df_resampled = df_accel_data.resample('S').mean()\n",
        "  df_resampled.reset_index(inplace=True)\n",
        "  df_resampled['seconds_elapsed'] = df_resampled['seconds_elapsed'].astype(int) / 1e6\n",
        "\n",
        "  df_resampled = df_resampled.drop(columns=['time','seconds_elapsed'])\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  # Selecting the axes, scaling them with MinMaxScaler\n",
        "  df_resampled[['z', 'y', 'x']] = scaler.fit_transform(df_resampled[['z', 'y', 'x']])\n",
        "\n",
        "  df_resampled = np.transpose(df_resampled)\n",
        "\n",
        "  X.append(df_resampled)\n",
        "  y.append(label + str(random.randint(0,5)))\n",
        "\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "sy = set(y)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Development_Project/'\n",
        "write_ndarray_to_tsfile(data = X, path = file_path, problem_name='sample_data', class_label=sy,class_value_list=y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U7pFZz41TdlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End Result\n",
        "\n",
        "We now have an ndarray with a shape of (4,3,13); 4 Instances (I had 4 CSV Files in one folder), 3 Columns (X,Y, and Z) and 13 Timepoints (Recorded at 12 seconds but the 0th second is included).\n",
        "\n",
        "We can now record as many instances as we want, insert it into a folder of our choice and generate a time-series dataset.\n",
        "## Part 2\n",
        "However, not only are we going to record individual datasets (one for accelerometer and another for gyroscope), we also need to combine the two.\n",
        "\n",
        "As a result, we need to;\n",
        "* Be able to iterate through folders\n",
        "* differentiate between Accelerometer and Gyroscope csv files\n",
        "* rename the columns and combine the two dataframes together to count as one instance!\n",
        "\n"
      ],
      "metadata": {
        "id": "0kp_AijKaiA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "dir_path = '/content/drive/MyDrive/Development_Project/dummy_data/'\n",
        "files = os.listdir(path)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for root,files,dir in os.walk(dir_path): #This allows us to walk through the folder that has more folders(instances)\n",
        "  for name in files: #Gets the name of the folders\n",
        "    path = os.path.join(dir_path,name)\n",
        "    folder_files = os.listdir(path)\n",
        "    count = 0\n",
        "    df_list = []\n",
        "    for file in folder_files: #Grabs the individual names of the files within that folder\n",
        "      file_name = file.split(\".\") #Allows us to split the name of the file from the file type extension\n",
        "      #Standard Preprocessing from earlier\n",
        "      df_accel_data = pd.read_csv(os.path.join(path,file))\n",
        "      df_accel_data['seconds_elapsed'] = pd.to_datetime(df_accel_data['seconds_elapsed'], unit='s')\n",
        "      df_accel_data.set_index('seconds_elapsed', inplace=True)\n",
        "      df_resampled = df_accel_data.resample('S').mean()\n",
        "      df_resampled.reset_index(inplace=True)\n",
        "      df_resampled['seconds_elapsed'] = df_resampled['seconds_elapsed'].astype(int) / 1e6\n",
        "      df_resampled = df_resampled.drop(columns=['time','seconds_elapsed'])\n",
        "      #By using .split(), we can get the name of the file and rename the columns as neccessary.\n",
        "      if(file_name[0] == \"Accelerometer\"):\n",
        "        df_resampled.rename(columns={\"z\":\"accel_z\", \"y\": \"accel_y\", \"x\": \"accel_x\"},inplace=True)\n",
        "        print(df_resampled.columns)\n",
        "        scaler = MinMaxScaler()\n",
        "        # Selecting the RENAMED axes\n",
        "        df_resampled[['accel_z', 'accel_y', 'accel_x']] = scaler.fit_transform(df_resampled[['accel_z', 'accel_y', 'accel_x']])\n",
        "      else: #Same process for Gyroscope\n",
        "        df_resampled.rename(columns={\"z\": \"gyro_z\", \"y\": \"gyro_y\", \"x\": \"gyro_x\"},inplace=True)\n",
        "        print(df_resampled.columns)\n",
        "        scaler = MinMaxScaler()\n",
        "        df_resampled[['gyro_z', 'gyro_y', 'gyro_x']] = scaler.fit_transform(df_resampled[['gyro_z', 'gyro_y', 'gyro_x']])\n",
        "\n",
        "      df_list.append(df_resampled)\n",
        "      count += 1\n",
        "\n",
        "    df_total = pd.concat(df_list, axis=1, join='inner')\n",
        "    df_total = np.transpose(df_total)\n",
        "    X.append(df_total)\n",
        "    y.append(label + str(random.randint(0,10)))\n",
        "\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "sy = set(y)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Development_Project/'\n",
        "write_ndarray_to_tsfile(data = X, path = file_path, problem_name='sample_data_combined', class_label=sy,class_value_list=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXsP0EepsG_j",
        "outputId": "d291568f-1e62-4ccf-f2ae-655b324c7ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['accel_z', 'accel_y', 'accel_x'], dtype='object')\n",
            "Index(['gyro_z', 'gyro_y', 'gyro_x'], dtype='object')\n",
            "Index(['accel_z', 'accel_y', 'accel_x'], dtype='object')\n",
            "Index(['gyro_z', 'gyro_y', 'gyro_x'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jGSQlsd1gl8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Second Instances\n",
        "\n",
        "My goal here is to be able to collect 2 second instances (roughly the time it takes to perform a dribble move) from one set of data so that I can get more accurate results of the movement being performed than taking 10 seconds (for example) of data which includes me performing the move multiple times.\n",
        "\n",
        "If we were to do this, Resampling no longer becomes necessary. This is because resampling includes taking the mean average of the occurences within that single second that was recorded. If we are taking 2 second instances, we wat those 2 seconds to be as precise as possible. As a result, we remove the resampling process."
      ],
      "metadata": {
        "id": "dG5yM1KEgoef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First Attempt\n",
        "\n",
        "Issue: Due to instances of different lenghts, we cannot continue the final conversion of turning X into an Array."
      ],
      "metadata": {
        "id": "NOJ46yhhwfeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dir_path = '/content/drive/MyDrive/Development_Project/dummy_data/'\n",
        "files = os.listdir(dir_path)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "df_accel_total = []\n",
        "df_gyro_total = []\n",
        "\n",
        "for root,files,dir in os.walk(dir_path): #This allows us to walk through the folder that has more folders(instances)\n",
        "  for name in files: #Gets the name of the folders\n",
        "    path = os.path.join(dir_path,name)\n",
        "    folder_files = os.listdir(path)\n",
        "    for file in folder_files: #Grabs the individual names of the files within that folder\n",
        "      file_name = file.split(\".\") #Allows us to split the name of the file from the file type extension\n",
        "      counter_split = 2\n",
        "      index_holder = 0;\n",
        "      print(file_name[0])\n",
        "      #Standard Preprocessing from earlier\n",
        "      df_accel_data = pd.read_csv(os.path.join(path,file))\n",
        "      for index,row in df_accel_data.iterrows():\n",
        "        if(math.floor(row['seconds_elapsed']) == counter_split ):\n",
        "          df_temp = df_accel_data.iloc[index_holder:index,:]\n",
        "          index_holder = index\n",
        "          counter_split += 2\n",
        "\n",
        "          df_temp = df_temp.drop(columns=['time','seconds_elapsed'])\n",
        "          #By using .split(), we can get the name of the file and rename the columns as neccessary.\n",
        "          if(file_name[0] == \"Accelerometer\"):\n",
        "            df_temp.rename(columns={\"z\":\"accel_z\", \"y\": \"accel_y\", \"x\": \"accel_x\"},inplace=True)\n",
        "            print(df_temp)\n",
        "            scaler = MinMaxScaler()\n",
        "            # Selecting the RENAMED axes\n",
        "            df_temp[['accel_z', 'accel_y', 'accel_x']] = scaler.fit_transform(df_temp[['accel_z', 'accel_y', 'accel_x']])\n",
        "            df_accel_total.append(df_temp)\n",
        "          else: #Same process for Gyroscope\n",
        "            df_temp.rename(columns={\"z\": \"gyro_z\", \"y\": \"gyro_y\", \"x\": \"gyro_x\"},inplace=True)\n",
        "            print(df_temp)\n",
        "            scaler = MinMaxScaler()\n",
        "            df_temp[['gyro_z', 'gyro_y', 'gyro_x']] = scaler.fit_transform(df_temp[['gyro_z', 'gyro_y', 'gyro_x']])\n",
        "            df_gyro_total.append(df_temp)\n",
        "\n",
        "\n",
        "\n",
        "index = 0\n",
        "for item in df_accel_total:\n",
        "  df_list = []\n",
        "  df_list.append(df_accel_total[index])\n",
        "  df_list.append(df_gyro_total[index])\n",
        "  df_total = pd.concat(df_list, axis=1, join='inner')\n",
        "  df_total = np.transpose(df_total)\n",
        "  X.append(df_total)\n",
        "  y.append(label + str(random.randint(0,10)))\n",
        "  index += 1\n",
        "\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "sy = set(y)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Development_Project/'\n",
        "write_ndarray_to_tsfile(data = X, path = file_path, problem_name='sample_data_combined', class_label=sy,class_value_list=y)"
      ],
      "metadata": {
        "id": "4MnA5A6DglVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8646aff-2172-41af-fa2e-2a03e1b84cf7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accelerometer\n",
            "    accel_z   accel_y   accel_x\n",
            "0  1.338586 -1.456287  0.995221\n",
            "1  2.134468 -0.402921  0.511669\n",
            "2  1.566823  1.207753  0.356628\n",
            "3 -3.274407 -4.050470 -0.954763\n",
            "4  9.090763  1.645252  8.305042\n",
            "      accel_z   accel_y   accel_x\n",
            "5   11.810346 -2.655034  6.780014\n",
            "6    3.668150  0.259544  9.171693\n",
            "7    2.495482 -0.821216  7.364952\n",
            "8    6.688351 -5.408457 -1.667495\n",
            "9   18.131771 -2.222675  1.849996\n",
            "10  -8.877424  0.072896 -1.635194\n",
            "      accel_z   accel_y   accel_x\n",
            "11  10.259792 -4.249830 -0.630009\n",
            "12   9.550881 -1.230097  2.687378\n",
            "13  14.077687 -0.613041  7.859201\n",
            "14  -5.744693 -4.368533 -8.355460\n",
            "15  -8.133892 -5.418841 -5.295728\n",
            "16  -2.963998 -1.695791  4.488464\n",
            "     accel_z   accel_y   accel_x\n",
            "17  0.984179 -0.244292  0.350111\n",
            "18 -1.756842 -0.115461  0.394145\n",
            "19  1.895712 -5.185919 -0.561691\n",
            "20 -2.518353 -2.369159 -1.055237\n",
            "21  0.219545 -1.029243 -0.612476\n",
            "     accel_z   accel_y   accel_x\n",
            "22  0.776889 -1.488166 -0.035596\n",
            "23  0.496181 -1.937151  0.172148\n",
            "24  6.032318 -1.259410  0.132535\n",
            "25  0.173649 -1.047496  0.720200\n",
            "26  0.494521 -0.783736  0.382337\n",
            "27  1.238393 -1.202816  0.110357\n",
            "     accel_z   accel_y   accel_x\n",
            "28  0.540272 -1.301648  0.064703\n",
            "29  0.328919 -1.262321  0.061259\n",
            "30  0.172853 -0.586289  0.033331\n",
            "31 -0.222043  0.265197  0.117771\n",
            "32 -0.483176  0.047005  0.014814\n",
            "Gyroscope\n",
            "     gyro_z    gyro_y    gyro_x\n",
            "0  1.338586 -1.456287  0.995221\n",
            "1  2.134468 -0.402921  0.511669\n",
            "2  1.566823  1.207753  0.356628\n",
            "3 -3.274407 -4.050470 -0.954763\n",
            "4  9.090763  1.645252  8.305042\n",
            "       gyro_z    gyro_y    gyro_x\n",
            "5   11.810346 -2.655034  6.780014\n",
            "6    3.668150  0.259544  9.171693\n",
            "7    2.495482 -0.821216  7.364952\n",
            "8    6.688351 -5.408457 -1.667495\n",
            "9   18.131771 -2.222675  1.849996\n",
            "10  -8.877424  0.072896 -1.635194\n",
            "       gyro_z    gyro_y    gyro_x\n",
            "11  10.259792 -4.249830 -0.630009\n",
            "12   9.550881 -1.230097  2.687378\n",
            "13  14.077687 -0.613041  7.859201\n",
            "14  -5.744693 -4.368533 -8.355460\n",
            "15  -8.133892 -5.418841 -5.295728\n",
            "16  -2.963998 -1.695791  4.488464\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "17  0.984179 -0.244292  0.350111\n",
            "18 -1.756842 -0.115461  0.394145\n",
            "19  1.895712 -5.185919 -0.561691\n",
            "20 -2.518353 -2.369159 -1.055237\n",
            "21  0.219545 -1.029243 -0.612476\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "22  0.776889 -1.488166 -0.035596\n",
            "23  0.496181 -1.937151  0.172148\n",
            "24  6.032318 -1.259410  0.132535\n",
            "25  0.173649 -1.047496  0.720200\n",
            "26  0.494521 -0.783736  0.382337\n",
            "27  1.238393 -1.202816  0.110357\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "28  0.540272 -1.301648  0.064703\n",
            "29  0.328919 -1.262321  0.061259\n",
            "30  0.172853 -0.586289  0.033331\n",
            "31 -0.222043  0.265197  0.117771\n",
            "32 -0.483176  0.047005  0.014814\n",
            "Accelerometer\n",
            "    accel_z   accel_y   accel_x\n",
            "0  1.338586 -1.456287  0.995221\n",
            "1  2.134468 -0.402921  0.511669\n",
            "2  1.566823  1.207753  0.356628\n",
            "3 -3.274407 -4.050470 -0.954763\n",
            "4  9.090763  1.645252  8.305042\n",
            "      accel_z   accel_y   accel_x\n",
            "5   11.810346 -2.655034  6.780014\n",
            "6    3.668150  0.259544  9.171693\n",
            "7    2.495482 -0.821216  7.364952\n",
            "8    6.688351 -5.408457 -1.667495\n",
            "9   18.131771 -2.222675  1.849996\n",
            "10  -8.877424  0.072896 -1.635194\n",
            "      accel_z   accel_y   accel_x\n",
            "11  10.259792 -4.249830 -0.630009\n",
            "12   9.550881 -1.230097  2.687378\n",
            "13  14.077687 -0.613041  7.859201\n",
            "14  -5.744693 -4.368533 -8.355460\n",
            "15  -8.133892 -5.418841 -5.295728\n",
            "16  -2.963998 -1.695791  4.488464\n",
            "     accel_z   accel_y   accel_x\n",
            "17  0.984179 -0.244292  0.350111\n",
            "18 -1.756842 -0.115461  0.394145\n",
            "19  1.895712 -5.185919 -0.561691\n",
            "20 -2.518353 -2.369159 -1.055237\n",
            "21  0.219545 -1.029243 -0.612476\n",
            "     accel_z   accel_y   accel_x\n",
            "22  0.776889 -1.488166 -0.035596\n",
            "23  0.496181 -1.937151  0.172148\n",
            "24  6.032318 -1.259410  0.132535\n",
            "25  0.173649 -1.047496  0.720200\n",
            "26  0.494521 -0.783736  0.382337\n",
            "27  1.238393 -1.202816  0.110357\n",
            "     accel_z   accel_y   accel_x\n",
            "28  0.540272 -1.301648  0.064703\n",
            "29  0.328919 -1.262321  0.061259\n",
            "30  0.172853 -0.586289  0.033331\n",
            "31 -0.222043  0.265197  0.117771\n",
            "32 -0.483176  0.047005  0.014814\n",
            "Gyroscope\n",
            "     gyro_z    gyro_y    gyro_x\n",
            "0  1.338586 -1.456287  0.995221\n",
            "1  2.134468 -0.402921  0.511669\n",
            "2  1.566823  1.207753  0.356628\n",
            "3 -3.274407 -4.050470 -0.954763\n",
            "4  9.090763  1.645252  8.305042\n",
            "       gyro_z    gyro_y    gyro_x\n",
            "5   11.810346 -2.655034  6.780014\n",
            "6    3.668150  0.259544  9.171693\n",
            "7    2.495482 -0.821216  7.364952\n",
            "8    6.688351 -5.408457 -1.667495\n",
            "9   18.131771 -2.222675  1.849996\n",
            "10  -8.877424  0.072896 -1.635194\n",
            "       gyro_z    gyro_y    gyro_x\n",
            "11  10.259792 -4.249830 -0.630009\n",
            "12   9.550881 -1.230097  2.687378\n",
            "13  14.077687 -0.613041  7.859201\n",
            "14  -5.744693 -4.368533 -8.355460\n",
            "15  -8.133892 -5.418841 -5.295728\n",
            "16  -2.963998 -1.695791  4.488464\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "17  0.984179 -0.244292  0.350111\n",
            "18 -1.756842 -0.115461  0.394145\n",
            "19  1.895712 -5.185919 -0.561691\n",
            "20 -2.518353 -2.369159 -1.055237\n",
            "21  0.219545 -1.029243 -0.612476\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "22  0.776889 -1.488166 -0.035596\n",
            "23  0.496181 -1.937151  0.172148\n",
            "24  6.032318 -1.259410  0.132535\n",
            "25  0.173649 -1.047496  0.720200\n",
            "26  0.494521 -0.783736  0.382337\n",
            "27  1.238393 -1.202816  0.110357\n",
            "      gyro_z    gyro_y    gyro_x\n",
            "28  0.540272 -1.301648  0.064703\n",
            "29  0.328919 -1.262321  0.061259\n",
            "30  0.172853 -0.586289  0.033331\n",
            "31 -0.222043  0.265197  0.117771\n",
            "32 -0.483176  0.047005  0.014814\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (12, 6) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ecca0a87d05>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (12, 6) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYItNr0Yu2qS",
        "outputId": "7e2d94b5-d513-404d-efec-a0defb97a209"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[                0         1         2    3    4\n",
              " accel_z  0.373063  0.437428  0.391522  0.0  1.0\n",
              " accel_y  0.455462  0.640401  0.923188  0.0  1.0\n",
              " accel_x  0.210586  0.158365  0.141622  0.0  1.0\n",
              " gyro_z   0.373063  0.437428  0.391522  0.0  1.0\n",
              " gyro_y   0.455462  0.640401  0.923188  0.0  1.0\n",
              " gyro_x   0.210586  0.158365  0.141622  0.0  1.0,\n",
              "                5         6         7         8         9        10\n",
              " accel_z  0.765953  0.464493  0.421075  0.576314  1.000000  0.00000\n",
              " accel_y  0.485784  1.000000  0.809322  0.000000  0.562064  0.96707\n",
              " accel_x  0.779349  1.000000  0.833314  0.000000  0.324516  0.00298\n",
              " gyro_z   0.765953  0.464493  0.421075  0.576314  1.000000  0.00000\n",
              " gyro_y   0.485784  1.000000  0.809322  0.000000  0.562064  0.96707\n",
              " gyro_x   0.779349  1.000000  0.833314  0.000000  0.324516  0.00298,\n",
              "                11        12   13        14        15        16\n",
              " accel_z  0.828112  0.796196  1.0  0.107565  0.000000  0.232757\n",
              " accel_y  0.243250  0.871602  1.0  0.218550  0.000000  0.774699\n",
              " accel_x  0.476448  0.681040  1.0  0.000000  0.188702  0.792118\n",
              " gyro_z   0.828112  0.796196  1.0  0.107565  0.000000  0.232757\n",
              " gyro_y   0.243250  0.871602  1.0  0.218550  0.000000  0.774699\n",
              " gyro_x   0.476448  0.681040  1.0  0.000000  0.188702  0.792118,\n",
              "                17        18        19        20        21\n",
              " accel_z  0.793494  0.172519  1.000000  0.000000  0.620267\n",
              " accel_y  0.974592  1.000000  0.000000  0.555524  0.819783\n",
              " accel_x  0.969619  1.000000  0.340522  0.000000  0.305482\n",
              " gyro_z   0.793494  0.172519  1.000000  0.000000  0.620267\n",
              " gyro_y   0.974592  1.000000  0.000000  0.555524  0.819783\n",
              " gyro_x   0.969619  1.000000  0.340522  0.000000  0.305482,\n",
              "                22        23        24        25        26        27\n",
              " accel_z  0.102965  0.055052  1.000000  0.000000  0.054769  0.181738\n",
              " accel_y  0.389266  0.000000  0.587595  0.771322  1.000000  0.636662\n",
              " accel_x  0.000000  0.274868  0.222456  1.000000  0.552971  0.193112\n",
              " gyro_z   0.102965  0.055052  1.000000  0.000000  0.054769  0.181738\n",
              " gyro_y   0.389266  0.000000  0.587595  0.771322  1.000000  0.636662\n",
              " gyro_x   0.000000  0.274868  0.222456  1.000000  0.552971  0.193112,\n",
              "               28        29        30       31        32\n",
              " accel_z  1.00000  0.793490  0.640999  0.25515  0.000000\n",
              " accel_y  0.00000  0.025099  0.456560  1.00000  0.860744\n",
              " accel_x  0.48456  0.451110  0.179856  1.00000  0.000000\n",
              " gyro_z   1.00000  0.793490  0.640999  0.25515  0.000000\n",
              " gyro_y   0.00000  0.025099  0.456560  1.00000  0.860744\n",
              " gyro_x   0.48456  0.451110  0.179856  1.00000  0.000000,\n",
              "                 0         1         2    3    4\n",
              " accel_z  0.373063  0.437428  0.391522  0.0  1.0\n",
              " accel_y  0.455462  0.640401  0.923188  0.0  1.0\n",
              " accel_x  0.210586  0.158365  0.141622  0.0  1.0\n",
              " gyro_z   0.373063  0.437428  0.391522  0.0  1.0\n",
              " gyro_y   0.455462  0.640401  0.923188  0.0  1.0\n",
              " gyro_x   0.210586  0.158365  0.141622  0.0  1.0,\n",
              "                5         6         7         8         9        10\n",
              " accel_z  0.765953  0.464493  0.421075  0.576314  1.000000  0.00000\n",
              " accel_y  0.485784  1.000000  0.809322  0.000000  0.562064  0.96707\n",
              " accel_x  0.779349  1.000000  0.833314  0.000000  0.324516  0.00298\n",
              " gyro_z   0.765953  0.464493  0.421075  0.576314  1.000000  0.00000\n",
              " gyro_y   0.485784  1.000000  0.809322  0.000000  0.562064  0.96707\n",
              " gyro_x   0.779349  1.000000  0.833314  0.000000  0.324516  0.00298,\n",
              "                11        12   13        14        15        16\n",
              " accel_z  0.828112  0.796196  1.0  0.107565  0.000000  0.232757\n",
              " accel_y  0.243250  0.871602  1.0  0.218550  0.000000  0.774699\n",
              " accel_x  0.476448  0.681040  1.0  0.000000  0.188702  0.792118\n",
              " gyro_z   0.828112  0.796196  1.0  0.107565  0.000000  0.232757\n",
              " gyro_y   0.243250  0.871602  1.0  0.218550  0.000000  0.774699\n",
              " gyro_x   0.476448  0.681040  1.0  0.000000  0.188702  0.792118,\n",
              "                17        18        19        20        21\n",
              " accel_z  0.793494  0.172519  1.000000  0.000000  0.620267\n",
              " accel_y  0.974592  1.000000  0.000000  0.555524  0.819783\n",
              " accel_x  0.969619  1.000000  0.340522  0.000000  0.305482\n",
              " gyro_z   0.793494  0.172519  1.000000  0.000000  0.620267\n",
              " gyro_y   0.974592  1.000000  0.000000  0.555524  0.819783\n",
              " gyro_x   0.969619  1.000000  0.340522  0.000000  0.305482,\n",
              "                22        23        24        25        26        27\n",
              " accel_z  0.102965  0.055052  1.000000  0.000000  0.054769  0.181738\n",
              " accel_y  0.389266  0.000000  0.587595  0.771322  1.000000  0.636662\n",
              " accel_x  0.000000  0.274868  0.222456  1.000000  0.552971  0.193112\n",
              " gyro_z   0.102965  0.055052  1.000000  0.000000  0.054769  0.181738\n",
              " gyro_y   0.389266  0.000000  0.587595  0.771322  1.000000  0.636662\n",
              " gyro_x   0.000000  0.274868  0.222456  1.000000  0.552971  0.193112,\n",
              "               28        29        30       31        32\n",
              " accel_z  1.00000  0.793490  0.640999  0.25515  0.000000\n",
              " accel_y  0.00000  0.025099  0.456560  1.00000  0.860744\n",
              " accel_x  0.48456  0.451110  0.179856  1.00000  0.000000\n",
              " gyro_z   1.00000  0.793490  0.640999  0.25515  0.000000\n",
              " gyro_y   0.00000  0.025099  0.456560  1.00000  0.860744\n",
              " gyro_x   0.48456  0.451110  0.179856  1.00000  0.000000]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Second Attempt"
      ],
      "metadata": {
        "id": "ozvuPJn0wptO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataframe(df, chunk_size = 10000):\n",
        "    chunks = list()\n",
        "    num_chunks = len(df) // chunk_size + 1\n",
        "    for i in range(num_chunks):\n",
        "      if(len(df[i*chunk_size:(i+1)*chunk_size]) < 3):\n",
        "        print((len(df[i*chunk_size:(i+1)*chunk_size])))\n",
        "        pass\n",
        "      else:\n",
        "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
        "    #print(num_chunks)\n",
        "    return chunks\n",
        "\n",
        "def find_chunks(df):\n",
        "  sum = 0\n",
        "  counter = 0\n",
        "  counter_split = 2\n",
        "  index_holder = 0\n",
        "  for index,row in df.iterrows():\n",
        "    if(round(row['seconds_elapsed']) == counter_split ):\n",
        "      sum += len(df_accel_data.iloc[index_holder:index,:])\n",
        "      index_holder = index\n",
        "      counter_split += 2\n",
        "      counter += 1\n",
        "  chunk_amount = round(sum / counter)\n",
        "\n",
        "  return chunk_amount"
      ],
      "metadata": {
        "id": "tUwO69ZJzACQ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import numpy\n",
        "dir_path = '/content/drive/MyDrive/Development_Project/dummy_data/'\n",
        "files = os.listdir(path)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for root,files,dir in os.walk(dir_path): #This allows us to walk through the folder that has more folders(instances)\n",
        "  for name in files: #Gets the name of the folders\n",
        "    path = os.path.join(dir_path,name)\n",
        "    folder_files = os.listdir(path)\n",
        "    count = 0\n",
        "    df_list = []\n",
        "    for file in folder_files: #Grabs the individual names of the files within that folder\n",
        "      file_name = file.split(\".\") #Allows us to split the name of the file from the file type extension\n",
        "      #Standard Preprocessing from earlier\n",
        "      df_resampled = pd.read_csv(os.path.join(path,file))\n",
        "      #By using .split(), we can get the name of the file and rename the columns as neccessary.\n",
        "      if(file_name[0] == \"Accelerometer\"):\n",
        "        df_resampled.rename(columns={\"z\":\"accel_z\", \"y\": \"accel_y\", \"x\": \"accel_x\"},inplace=True)\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        # Selecting the RENAMED axes\n",
        "        df_resampled[['accel_z', 'accel_y', 'accel_x']] = scaler.fit_transform(df_resampled[['accel_z', 'accel_y', 'accel_x']])\n",
        "      else:#Same process for Gyroscope\n",
        "        df_resampled = df_resampled.drop(columns=['time','seconds_elapsed'])\n",
        "        df_resampled.rename(columns={\"z\": \"gyro_z\", \"y\": \"gyro_y\", \"x\": \"gyro_x\"},inplace=True)\n",
        "        scaler = MinMaxScaler()\n",
        "        df_resampled[['gyro_z', 'gyro_y', 'gyro_x']] = scaler.fit_transform(df_resampled[['gyro_z', 'gyro_y', 'gyro_x']])\n",
        "\n",
        "      df_list.append(df_resampled)\n",
        "      count += 1\n",
        "\n",
        "\n",
        "    df_total = pd.concat(df_list, axis=1, join='inner')\n",
        "    chunk = find_chunks(df_total)\n",
        "    df_chunk = split_dataframe(df_total, chunk_size=chunk)\n",
        "    for df in df_chunk:\n",
        "      if(len(df) < chunk):\n",
        "        pass\n",
        "      else:\n",
        "        print(len(df))\n",
        "        df= df.drop(columns=['time','seconds_elapsed'])\n",
        "        df = np.transpose(df)\n",
        "        X.append(df)\n",
        "        y.append(label + str(random.randint(0,10)))\n",
        "\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "sy = set(y)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Development_Project/'\n",
        "write_ndarray_to_tsfile(data = X, path = file_path, problem_name='sample_data_combined', class_label=sy,class_value_list=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvvOj_kAwofG",
        "outputId": "8b220b1b-adf5-468b-911c-72d4231a96c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "id": "HaT-t_26zbFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70adb130-7661-4517-a059-a1fc9f69dec0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37824193, 0.40770901, 0.38669228, 0.2074485 , 0.66526185],\n",
              "       [0.56094309, 0.71005857, 0.93806714, 0.19370801, 1.        ],\n",
              "       [0.53349686, 0.5059081 , 0.49706236, 0.42224181, 0.95055383],\n",
              "       [0.37824193, 0.40770901, 0.38669228, 0.2074485 , 0.66526185],\n",
              "       [0.56094309, 0.71005857, 0.93806714, 0.19370801, 1.        ],\n",
              "       [0.53349686, 0.5059081 , 0.49706236, 0.42224181, 0.95055383]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P1lWDqfMEoFm"
      ],
      "history_visible": true,
      "mount_file_id": "1oglg7EJlqlXwGF1dmEQUmY1JJY3aZ6-y",
      "authorship_tag": "ABX9TyPayIm3h3hnqZeBV+eZKEAa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}